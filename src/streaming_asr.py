import sounddevice as sd
import queue
import numpy as np
from scipy.io.wavfile import write
from google.cloud import speech
from datetime import datetime
import os
import threading

# === è¨­å®š ===
samplerate = 16000
channels = 1
dtype = 'int16'
block_duration = 0.5  # ç§’
save_dir = "streaming_logs"
os.makedirs(save_dir, exist_ok=True)

# === ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ===
audio_queue = queue.Queue()
recorded_blocks = []
final_texts = []

# === éŸ³å£°å…¥åŠ›ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ ===
def callback(indata, frames, time, status):
    if status:
        print("âš ï¸", status)
    audio_queue.put(bytes(indata))
    recorded_blocks.append(indata.copy())

# === éŸ³å£°ãƒªã‚¯ã‚¨ã‚¹ãƒˆç”Ÿæˆ ===
def request_generator():
    while True:
        data = audio_queue.get()
        if data is None:
            break
        yield speech.StreamingRecognizeRequest(audio_content=data)

# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===
def main():
    print("ğŸ™ Enter ã§éŒ²éŸ³é–‹å§‹...")
    input()
    print("ğŸ¤ éŒ²éŸ³ä¸­ï¼ˆEnterã§çµ‚äº†ï¼‰")

    with sd.InputStream(samplerate=samplerate, channels=channels, dtype=dtype, callback=callback):
        responses = client.streaming_recognize(config=streaming_config, requests=request_generator())
        def listen_print_loop():
            try:
                for response in responses:
                    for result in response.results:
                        transcript = result.alternatives[0].transcript
                        if result.is_final:
                            print("âœ…", transcript)
                            final_texts.append(transcript)
                        else:
                            print("ğŸ”„", transcript, end="\r")  # æš«å®šçµæœï¼ˆä¸Šæ›¸ãè¡¨ç¤ºï¼‰
            except Exception as e:
                print("âš ï¸ èªè­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)



        # éåŒæœŸã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¡¨ç¤º
        print_thread = threading.Thread(target=listen_print_loop)
        print_thread.start()

        input()  # éŒ²éŸ³åœæ­¢ã® Enter
        audio_queue.put(None)
        print_thread.join()

    # ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    wav_path = os.path.join(save_dir, f"{timestamp}.wav")
    txt_path = os.path.join(save_dir, f"{timestamp}.txt")
    audio_np = np.concatenate(recorded_blocks, axis=0)
    write(wav_path, samplerate, audio_np)
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write("\n".join(final_texts))
    print(f"\nğŸ’¾ éŸ³å£°: {wav_path}")
    print(f"ğŸ“ èªè­˜çµæœ: {txt_path}")

# === Google Cloud Speech-to-Text ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š ===
client = speech.SpeechClient()
config = speech.RecognitionConfig(
    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
    sample_rate_hertz=samplerate,
    language_code="ja-JP",
)
streaming_config = speech.StreamingRecognitionConfig(
    config=config,
    interim_results=True  # æš«å®šçµæœã¯è¡¨ç¤ºã—ãªã„
)

if __name__ == "__main__":
    main()

