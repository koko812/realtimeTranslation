import sounddevice as sd
from scipy.io.wavfile import write
import numpy as np
import threading
import sys
import os
from google.cloud import speech
import tempfile

# Enter ã§éŒ²éŸ³é–‹å§‹ã—ã¦ï¼Œã‚‚ã†ä¸€åº¦æŠ¼ã™ã¨éŒ²éŸ³çµ‚äº†
# ãã—ã¦ google asr api ã«é€ã‚‰ã‚Œã¦éŸ³å£°èªè­˜

samplerate = 16000
channels = 1
dtype = 'int16'

recording = []
recording_flag = False

def input_thread():
    global recording_flag
    input("ğŸ™ï¸ Enter ã‚’æŠ¼ã™ã¨éŒ²éŸ³é–‹å§‹ã—ã¾ã™ï¼ˆã‚‚ã†ä¸€åº¦æŠ¼ã™ã¨çµ‚äº†ï¼‰: ")
    recording_flag = True
    print("ğŸ”´ éŒ²éŸ³ä¸­... Enter ã§åœæ­¢")
    input()
    recording_flag = False
    print("â¹ï¸ éŒ²éŸ³åœæ­¢")

def record_audio_dynamic():
    global recording, recording_flag
    block_duration = 0.5  # ç§’å˜ä½

    def callback(indata, frames, time, status):
        if recording_flag:
            recording.append(indata.copy())

    stream = sd.InputStream(
        samplerate=samplerate,
        channels=channels,
        dtype=dtype,
        callback=callback,
        blocksize=int(samplerate * block_duration),
    )

    with stream:
        input_thread()

    audio_np = np.concatenate(recording, axis=0)
    return audio_np

from datetime import datetime
import os

def transcribe_audio(array, samplerate, lang='ja-JP', save_dir="../recordings"):
    os.makedirs(save_dir, exist_ok=True)

    client = speech.SpeechClient()

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    wav_path = os.path.join(save_dir, f"{timestamp}.wav")
    txt_path = os.path.join(save_dir, f"{timestamp}.txt")

    # éŒ²éŸ³ã‚’ä¿å­˜
    write(wav_path, samplerate, array)

    # èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    with open(wav_path, "rb") as f:
        audio_data = f.read()

    audio = speech.RecognitionAudio(content=audio_data)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=samplerate,
        language_code=lang,
    )

    print("ğŸ§  èªè­˜ä¸­...")
    response = client.recognize(config=config, audio=audio)

    transcripts = []
    if response.results:
        for result in response.results:
            t = result.alternatives[0].transcript
            print("ğŸ“ èªè­˜çµæœ:", t)
            transcripts.append(t)
    else:
        print("âš ï¸ èªè­˜çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    # çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ä¿å­˜
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write("\n".join(transcripts))
    print(f"âœ… éŸ³å£°ãƒ»ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {wav_path}, {txt_path}")


if __name__ == "__main__":
    audio_data = record_audio_dynamic()
    transcribe_audio(audio_data, samplerate)

